name: RL Training (GPU)

on:
  push:
    paths:
      - 'blokus-engine/training_queue.json'
    branches:
      - 'xp/**'
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write
  actions: write

env:
  PYTHON_VERSION: "3.11"

jobs:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Parse training queue
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  setup:
    name: ðŸ”§ Parse training configuration
    runs-on: ubuntu-latest
    outputs:
      experiment_name: ${{ steps.parse.outputs.experiment_name }}
      board_size: ${{ steps.parse.outputs.board_size }}
      episodes: ${{ steps.parse.outputs.episodes }}
      eval_frequency: ${{ steps.parse.outputs.eval_frequency }}
      eval_games: ${{ steps.parse.outputs.eval_games }}
      log_frequency: ${{ steps.parse.outputs.log_frequency }}
      min_buffer_size: ${{ steps.parse.outputs.min_buffer_size }}
      resume: ${{ steps.parse.outputs.resume }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Parse training queue
        id: parse
        run: |
          QUEUE_FILE="blokus-engine/training_queue.json"
          
          if [ ! -f "$QUEUE_FILE" ]; then
            echo "âŒ Training queue file not found"
            exit 1
          fi
          
          QUEUE_LENGTH=$(jq '.queue | length' "$QUEUE_FILE")
          
          if [ "$QUEUE_LENGTH" -eq 0 ]; then
            echo "â„¹ï¸ Training queue is empty, skipping"
            echo "experiment_name=none" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          
          # Get first item from queue
          EXP_NAME=$(jq -r '.queue[0].experiment_name' "$QUEUE_FILE")
          BOARD_SIZE=$(jq -r '.queue[0].board_size // "14"' "$QUEUE_FILE")
          EPISODES=$(jq -r '.queue[0].episodes // "1000"' "$QUEUE_FILE")
          EVAL_FREQ=$(jq -r '.queue[0].eval_frequency // "100"' "$QUEUE_FILE")
          EVAL_GAMES=$(jq -r '.queue[0].eval_games // "50"' "$QUEUE_FILE")
          LOG_FREQ=$(jq -r '.queue[0].log_frequency // "10"' "$QUEUE_FILE")
          MIN_BUFFER=$(jq -r '.queue[0].min_buffer_size // "1000"' "$QUEUE_FILE")
          RESUME=$(jq -r '.queue[0].resume // "false"' "$QUEUE_FILE")
          
          echo "ðŸ“‹ Training Configuration:"
          echo "  Experiment: $EXP_NAME"
          echo "  Board: ${BOARD_SIZE}x${BOARD_SIZE}"
          echo "  Episodes: $EPISODES"
          echo "  Eval Frequency: $EVAL_FREQ"
          echo "  Eval Games: $EVAL_GAMES"
          echo "  Log Frequency: $LOG_FREQ"
          echo "  Min Buffer: $MIN_BUFFER"
          echo "  Resume: $RESUME"
          
          echo "experiment_name=$EXP_NAME" >> "$GITHUB_OUTPUT"
          echo "board_size=$BOARD_SIZE" >> "$GITHUB_OUTPUT"
          echo "episodes=$EPISODES" >> "$GITHUB_OUTPUT"
          echo "eval_frequency=$EVAL_FREQ" >> "$GITHUB_OUTPUT"
          echo "eval_games=$EVAL_GAMES" >> "$GITHUB_OUTPUT"
          echo "log_frequency=$LOG_FREQ" >> "$GITHUB_OUTPUT"
          echo "min_buffer_size=$MIN_BUFFER" >> "$GITHUB_OUTPUT"
          echo "resume=$RESUME" >> "$GITHUB_OUTPUT"

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # GPU Training on Occidata
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  train:
    name: ðŸš€ RL Training (GPU)
    runs-on: [self-hosted, blokus, occidata]
    needs: [setup]
    if: needs.setup.outputs.experiment_name != 'none'
    
    env:
      JULIA_DEPOT_PATH: /projects/ctb/blokus-runner/julia_depot
      
    outputs:
      experiment_dir: ${{ steps.collect.outputs.experiment_dir }}
      best_win_rate: ${{ steps.collect.outputs.best_win_rate }}
      success: ${{ steps.collect.outputs.success }}
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4


      - name: ðŸ“¦ Setup Python environment
        run: |
          # Use persistent venv (pre-installed on runner)
          VENV_DIR="/projects/ctb/blokus-runner/blokus-venv"
          
          if [ ! -d "$VENV_DIR" ]; then
            echo "âŒ Persistent venv not found at $VENV_DIR"
            echo "   Please run: bash scripts/setup_runner_env.sh on the runner"
            exit 1
          fi
          
          source "$VENV_DIR/bin/activate"
          echo "âœ… Using persistent venv: $VENV_DIR"
          echo "   Python: $(python --version)"
          
          # Install/update blokus package (fast since deps are already installed)
          cd blokus-engine
          pip install -e ".[dev]" --quiet
          
          # Verify PyTorch
          python -c "import torch; print(f'âœ… PyTorch {torch.__version__} ready')"

      - name: ðŸ‹ï¸ Dispatch training to SLURM
        run: |
          cd blokus-engine
          WORKDIR=$(pwd)
          
          # Create SLURM dispatch script
          cat > dispatch_training.sh <<'EOF'
          #!/bin/bash
          set -euo pipefail
          
          WORKDIR="$1"
          SCRIPT_PATH="$2"
          EXP_NAME="$3"
          BOARD_SIZE="$4"
          EPISODES="$5"
          EVAL_FREQ="$6"
          EVAL_GAMES="$7"
          LOG_FREQ="$8"
          MIN_BUFFER="$9"
          
          JOB_SCRIPT=$(mktemp)
          cat > "$JOB_SCRIPT" <<SLURM
          #!/bin/bash
          #SBATCH --job-name=blokus-rl
          #SBATCH --partition=GPUNodes
          #SBATCH --gres=gpu:1080ti:1
          #SBATCH --cpus-per-task=4
          #SBATCH --mem=32G
          #SBATCH --time=06:00:00
          #SBATCH --output=$WORKDIR/slurm-%j.out
          #SBATCH --error=$WORKDIR/slurm-%j.err
          
          
          set -exo pipefail  # Removed -u to avoid unbound variable errors in /etc/profile
          
          echo "=========================================="
          echo "SLURM Job Starting"
          echo "=========================================="
          echo "Job ID: \$SLURM_JOB_ID"
          echo "Node: \$SLURM_NODELIST"
          echo "Working directory should be: $WORKDIR"
          echo ""
          
          echo "Step 0: Sourcing profile for module command..."
          source /etc/profile 2>/dev/null || true
          [ -f /etc/profile.d/modules.sh ] && source /etc/profile.d/modules.sh 2>/dev/null || true
          [ -f /etc/profile.d/lmod.sh ] && source /etc/profile.d/lmod.sh 2>/dev/null || true
          echo "Profile sourced"
          echo ""
          
          echo "Step 1: Loading CUDA module..."
          module load cuda/12.2
          echo "CUDA module loaded"
          echo ""
          
          echo "ðŸ“‚ Step 2: Changing to working directory..."
          echo "Before cd: \$(pwd)"
          cd $WORKDIR
          echo "After cd: \$(pwd)"
          echo "âœ… Changed to working directory"
          echo ""
          
          echo "ðŸ Step 3: Activating Python venv..."
          source /projects/ctb/blokus-runner/blokus-venv/bin/activate
          echo "Python: \$(which python)"
          echo "Python version: \$(python --version)"
          echo "âœ… Venv activated"
          echo ""
          
          echo "ðŸ” Step 4: GPU Information:"
          nvidia-smi
          echo ""
          
          echo "ðŸ“‹ Step 5: Listing files in working directory..."
          ls -la
          echo ""
          
          echo "ðŸŽ¯ Step 6: Starting training..."
          echo "Script path: $SCRIPT_PATH"
          echo "Experiment: $EXP_NAME"
          echo "Command: python -u $SCRIPT_PATH --new --name $EXP_NAME --board-size $BOARD_SIZE --episodes $EPISODES --eval-freq $EVAL_FREQ --eval-games $EVAL_GAMES --log-freq $LOG_FREQ --min-buffer $MIN_BUFFER --no-video"
          echo ""
          
          python -u "$SCRIPT_PATH" --new --name "$EXP_NAME" --board-size "$BOARD_SIZE" --episodes "$EPISODES" --eval-freq "$EVAL_FREQ" --eval-games "$EVAL_GAMES" --log-freq "$LOG_FREQ" --min-buffer "$MIN_BUFFER" --no-video | tee training_output.txt
          
          echo ""
          echo "âœ… Training completed"
          echo ""
          
          echo "ðŸ“Š Step 7: Processing results..."
          ACTUAL_EXP_DIR=\$(grep "EXPERIMENT_DIR=" training_output.txt | cut -d'=' -f2)
          echo "Experiment directory: \$ACTUAL_EXP_DIR"
          echo "EXPERIMENT_DIR=\$ACTUAL_EXP_DIR" > job_results.txt
          
          METADATA_FILE="\$ACTUAL_EXP_DIR/metadata.json"
          if [ -f "\$METADATA_FILE" ]; then
            BEST_WIN_RATE=\$(python -c "import json; print(json.load(open('\$METADATA_FILE'))['best_win_rate'])")
            echo "Best win rate: \$BEST_WIN_RATE"
            echo "BEST_WIN_RATE=\$BEST_WIN_RATE" >> job_results.txt
          else
            echo "âš ï¸  Metadata file not found"
            echo "BEST_WIN_RATE=0.0" >> job_results.txt
          fi
          
          echo ""
          echo "=========================================="
          echo "âœ… SLURM Job Completed Successfully"
          echo "=========================================="
          SLURM
          
          JOB_ID=$(sbatch --parsable "$JOB_SCRIPT")
          echo "ðŸ†” SLURM Job ID: $JOB_ID"
          echo "ðŸ“‚ Output file: $WORKDIR/slurm-${JOB_ID}.out"
          echo "ðŸ“‚ Error file: $WORKDIR/slurm-${JOB_ID}.err"
          
          # Wait for output file to be created
          echo "â³ Waiting for SLURM job to start..."
          WAIT_COUNT=0
          while [ ! -f "$WORKDIR/slurm-${JOB_ID}.out" ] && [ $WAIT_COUNT -lt 60 ]; do
            sleep 2
            WAIT_COUNT=$((WAIT_COUNT + 1))
          done
          
          if [ -f "$WORKDIR/slurm-${JOB_ID}.out" ]; then
            echo "âœ… Output file created, streaming output..."
            echo "=========================================="
            
            # Tail output in background
            tail -f "$WORKDIR/slurm-${JOB_ID}.out" &
            TAIL_PID=$!
            
            # Wait for job completion
            while squeue -j $JOB_ID 2>/dev/null | grep -q $JOB_ID; do
              sleep 30
            done
            
            # Kill tail process
            kill $TAIL_PID 2>/dev/null || true
            sleep 1
            
            echo "=========================================="
            echo "ðŸ“‹ Final output (ensuring nothing was missed):"
            cat "$WORKDIR/slurm-${JOB_ID}.out"
          else
            echo "âš ï¸  Output file not created after 2 minutes"
            echo "Checking job status..."
          fi
          
          # Check status
          echo ""
          
          # Always show stderr for debugging
          if [ -s "$WORKDIR/slurm-${JOB_ID}.err" ]; then
            echo "âš ï¸  SLURM Job Errors/Warnings:"
            cat "$WORKDIR/slurm-${JOB_ID}.err"
            echo ""
          fi
          
          if sacct -j $JOB_ID --format=State --noheader | grep -q "COMPLETED"; then
            echo "âœ… Job completed successfully"
            
            # Debug: show what files were created
            echo ""
            echo "ðŸ“ Files in workspace:"
            ls -lh "$WORKDIR/" | grep -E "(slurm|job_results|training_output)" || echo "No relevant files found"
            
            # Check if output is actually empty
            if [ ! -s "$WORKDIR/slurm-${JOB_ID}.out" ]; then
              echo ""
              echo "âŒ WARNING: Output file is empty!"
              echo "This usually means the SLURM job failed to execute properly."
              exit 1
            fi
            
            exit 0
          else
            echo "âŒ Job failed"
            echo "ðŸ“‹ SLURM Job Errors:"
            cat "$WORKDIR/slurm-${JOB_ID}.err" 2>/dev/null || echo "(no stderr)"
            exit 1
          fi
          EOF
          
          chmod +x dispatch_training.sh
          ./dispatch_training.sh \
            "$WORKDIR" \
            "scripts/train.py" \
            "${{ needs.setup.outputs.experiment_name }}" \
            "${{ needs.setup.outputs.board_size }}" \
            "${{ needs.setup.outputs.episodes }}" \
            "${{ needs.setup.outputs.eval_frequency }}" \
            "${{ needs.setup.outputs.eval_games }}" \
            "${{ needs.setup.outputs.log_frequency }}" \
            "${{ needs.setup.outputs.min_buffer_size }}"

      - name: ðŸ“Š Collect results
        id: collect
        if: always()
        run: |
          cd blokus-engine
          
          if [ -f "job_results.txt" ]; then
            source job_results.txt
            echo "experiment_dir=$EXPERIMENT_DIR" >> "$GITHUB_OUTPUT"
            echo "best_win_rate=$BEST_WIN_RATE" >> "$GITHUB_OUTPUT"
            echo "success=true" >> "$GITHUB_OUTPUT"
            
            # Generate plots
            source /projects/ctb/blokus-runner/blokus-venv/bin/activate
            METRICS_FILE="$EXPERIMENT_DIR/metrics.csv"
            if [ -f "$METRICS_FILE" ]; then
              python scripts/plot_metrics.py "$METRICS_FILE"
            fi
          else
            echo "success=false" >> "$GITHUB_OUTPUT"
          fi

      - name: ðŸ“¦ Upload training artifacts
        if: steps.collect.outputs.success == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: training-results-gpu
          path: |
            ${{ steps.collect.outputs.experiment_dir }}/model.pt
            ${{ steps.collect.outputs.experiment_dir }}/metadata.json
            ${{ steps.collect.outputs.experiment_dir }}/metrics.csv
            ${{ steps.collect.outputs.experiment_dir }}/training_plot.png
          retention-days: 30

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Commit results
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  commit-results:
    name: ðŸ’¾ Commit training results
    runs-on: ubuntu-latest
    needs: [train]
    if: needs.train.outputs.success == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download training artifacts
        uses: actions/download-artifact@v4
        with:
          name: training-results-gpu
          path: ${{ needs.train.outputs.experiment_dir }}

      - name: Commit and push results
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          git add ${{ needs.train.outputs.experiment_dir }}
          git commit -m "ðŸ¤– GPU Training results: ${{ needs.train.outputs.experiment_dir }}
          
          Best win rate: ${{ needs.train.outputs.best_win_rate }}
          Trained on: Occidata GPU (GTX 1080 Ti)" || echo "No changes to commit"
          
          git push || echo "Nothing to push"
