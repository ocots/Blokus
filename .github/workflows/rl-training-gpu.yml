name: RL Training (GPU-Optimized)

on:
  push:
    paths:
      - 'blokus-engine/training_queue.json'
    branches:
      - 'xp/**'
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write
  actions: write

env:
  PYTHON_VERSION: "3.11"

jobs:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Determine if Occidata GPU runner is available
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  determine-runner:
    name: ðŸ§­ Determine runner
    runs-on: ubuntu-latest
    outputs:
      runner: ${{ steps.pick.outputs.runner }}
      has_gpu: ${{ steps.pick.outputs.has_gpu }}
    steps:
      - name: Select runner
        id: pick
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          REPO="${{ github.repository }}"
          echo "ðŸ” Checking for online Occidata GPU runner in repo $REPO"
          
          TMP_ERR=$(mktemp)
          if MATCH=$(gh api "repos/$REPO/actions/runners" \
            --jq '.runners[] | select(.status=="online") | select([.labels[].name] | index("blokus")) | select([.labels[].name] | index("gpu"))' 2>"$TMP_ERR"); then
            if [ -n "$MATCH" ]; then
              SELECT='["self-hosted","blokus","gpu","occidata"]'
              HAS_GPU="true"
              echo "âœ… Occidata GPU runner available"
            else
              SELECT='["ubuntu-latest"]'
              HAS_GPU="false"
              echo "â„¹ï¸ No online GPU runner found, falling back to ubuntu-latest (CPU)"
            fi
          else
            STATUS=$?
            ERR_MSG=$(cat "$TMP_ERR" || true)
            echo "âš ï¸ Failed to query runners (exit $STATUS). Falling back to ubuntu-latest."
            if [ -n "$ERR_MSG" ]; then
              echo "$ERR_MSG"
            fi
            SELECT='["ubuntu-latest"]'
            HAS_GPU="false"
          fi
          rm -f "$TMP_ERR"
          echo "runner=$SELECT" >> "$GITHUB_OUTPUT"
          echo "has_gpu=$HAS_GPU" >> "$GITHUB_OUTPUT"

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Parse training queue
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  setup:
    name: ðŸ”§ Parse training configuration
    runs-on: ubuntu-latest
    needs: determine-runner
    outputs:
      experiment_name: ${{ steps.parse.outputs.experiment_name }}
      board_size: ${{ steps.parse.outputs.board_size }}
      episodes: ${{ steps.parse.outputs.episodes }}
      eval_frequency: ${{ steps.parse.outputs.eval_frequency }}
      eval_games: ${{ steps.parse.outputs.eval_games }}
      log_frequency: ${{ steps.parse.outputs.log_frequency }}
      min_buffer_size: ${{ steps.parse.outputs.min_buffer_size }}
      resume: ${{ steps.parse.outputs.resume }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Parse training queue
        id: parse
        run: |
          QUEUE_FILE="blokus-engine/training_queue.json"
          
          if [ ! -f "$QUEUE_FILE" ]; then
            echo "âŒ Training queue file not found"
            exit 1
          fi
          
          QUEUE_LENGTH=$(jq '.queue | length' "$QUEUE_FILE")
          
          if [ "$QUEUE_LENGTH" -eq 0 ]; then
            echo "â„¹ï¸ Training queue is empty, skipping"
            echo "experiment_name=none" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          
          # Get first item from queue
          EXP_NAME=$(jq -r '.queue[0].experiment_name' "$QUEUE_FILE")
          BOARD_SIZE=$(jq -r '.queue[0].board_size // "14"' "$QUEUE_FILE")
          EPISODES=$(jq -r '.queue[0].episodes // "1000"' "$QUEUE_FILE")
          EVAL_FREQ=$(jq -r '.queue[0].eval_frequency // "100"' "$QUEUE_FILE")
          EVAL_GAMES=$(jq -r '.queue[0].eval_games // "50"' "$QUEUE_FILE")
          LOG_FREQ=$(jq -r '.queue[0].log_frequency // "10"' "$QUEUE_FILE")
          MIN_BUFFER=$(jq -r '.queue[0].min_buffer_size // "1000"' "$QUEUE_FILE")
          RESUME=$(jq -r '.queue[0].resume // "false"' "$QUEUE_FILE")
          
          echo "ðŸ“‹ Training Configuration:"
          echo "  Experiment: $EXP_NAME"
          echo "  Board: ${BOARD_SIZE}x${BOARD_SIZE}"
          echo "  Episodes: $EPISODES"
          echo "  Eval Frequency: $EVAL_FREQ"
          echo "  Eval Games: $EVAL_GAMES"
          echo "  Log Frequency: $LOG_FREQ"
          echo "  Min Buffer: $MIN_BUFFER"
          echo "  Resume: $RESUME"
          
          echo "experiment_name=$EXP_NAME" >> "$GITHUB_OUTPUT"
          echo "board_size=$BOARD_SIZE" >> "$GITHUB_OUTPUT"
          echo "episodes=$EPISODES" >> "$GITHUB_OUTPUT"
          echo "eval_frequency=$EVAL_FREQ" >> "$GITHUB_OUTPUT"
          echo "eval_games=$EVAL_GAMES" >> "$GITHUB_OUTPUT"
          echo "log_frequency=$LOG_FREQ" >> "$GITHUB_OUTPUT"
          echo "min_buffer_size=$MIN_BUFFER" >> "$GITHUB_OUTPUT"
          echo "resume=$RESUME" >> "$GITHUB_OUTPUT"

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Training job (GPU or CPU)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  train:
    name: ðŸš€ RL Training
    runs-on: ${{ fromJson(needs.determine-runner.outputs.runner) }}
    needs: [determine-runner, setup]
    if: needs.setup.outputs.experiment_name != 'none'
    outputs:
      experiment_dir: ${{ steps.train.outputs.experiment_dir }}
      best_win_rate: ${{ steps.train.outputs.best_win_rate }}
      success: ${{ steps.train.outputs.success }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: ðŸ Setup Python (GitHub runner)
        if: contains(needs.determine-runner.outputs.runner, 'ubuntu-latest')
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: ðŸ“¦ Install dependencies (GitHub runner - CPU)
        if: contains(needs.determine-runner.outputs.runner, 'ubuntu-latest')
        run: |
          cd blokus-engine
          pip install --index-url https://download.pytorch.org/whl/cpu \
            torch torchvision --extra-index-url https://pypi.org/simple
          pip install -e ".[dev]"

      - name: ðŸ“¦ Install dependencies (Occidata - GPU)
        if: contains(needs.determine-runner.outputs.runner, 'self-hosted')
        shell: bash
        run: |
          set -euo pipefail
          cd blokus-engine
          
          # Load CUDA module
          module load cuda/12.2 || echo "âš ï¸ CUDA module not available"
          
          # Create venv if needed
          if [ ! -d ".venv" ]; then
            python3 -m venv .venv
          fi
          
          source .venv/bin/activate
          
          # Install PyTorch with CUDA support
          pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
          pip install -e ".[dev]"
          
          # Verify GPU
          python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"

      - name: ðŸ‹ï¸ Run training (GitHub CPU)
        if: contains(needs.determine-runner.outputs.runner, 'ubuntu-latest')
        id: train_cpu
        shell: bash
        run: |
          cd blokus-engine
          
          EXP_NAME="${{ needs.setup.outputs.experiment_name }}"
          RESUME="${{ needs.setup.outputs.resume }}"
          
          MODE_FLAG="--new"
          if [ "$RESUME" = "true" ]; then
            MODE_FLAG="--resume $EXP_NAME"
          fi
          
          python -u scripts/train.py \
            $MODE_FLAG \
            --name "$EXP_NAME" \
            --board-size "${{ needs.setup.outputs.board_size }}" \
            --episodes "${{ needs.setup.outputs.episodes }}" \
            --eval-freq "${{ needs.setup.outputs.eval_frequency }}" \
            --eval-games "${{ needs.setup.outputs.eval_games }}" \
            --log-freq "${{ needs.setup.outputs.log_frequency }}" \
            --min-buffer "${{ needs.setup.outputs.min_buffer_size }}" \
            --no-video | tee training_output.txt
          
          # Extract experiment directory
          ACTUAL_EXP_DIR=$(grep "EXPERIMENT_DIR=" training_output.txt | cut -d'=' -f2)
          echo "experiment_dir=$ACTUAL_EXP_DIR" >> "$GITHUB_OUTPUT"
          
          METADATA_FILE="$ACTUAL_EXP_DIR/metadata.json"
          if [ -f "$METADATA_FILE" ]; then
            BEST_WIN_RATE=$(python -c "import json; print(json.load(open('$METADATA_FILE'))['best_win_rate'])")
            echo "best_win_rate=$BEST_WIN_RATE" >> "$GITHUB_OUTPUT"
          else
            echo "best_win_rate=0.0" >> "$GITHUB_OUTPUT"
          fi
          echo "success=true" >> "$GITHUB_OUTPUT"

      - name: ðŸ‹ï¸ Run training (Occidata GPU via SLURM)
        if: contains(needs.determine-runner.outputs.runner, 'self-hosted')
        id: train_gpu
        shell: bash
        run: |
          cd blokus-engine
          
          # Create SLURM job script
          cat > train_gpu.sh <<'EOF'
          #!/bin/bash
          #SBATCH --job-name=blokus-rl
          #SBATCH --partition=GPUNodes
          #SBATCH --gres=gpu:1080ti:1
          #SBATCH --cpus-per-task=4
          #SBATCH --mem=32G
          #SBATCH --time=06:00:00
          #SBATCH --output=slurm-%j.out
          #SBATCH --error=slurm-%j.err
          
          set -euo pipefail
          module load cuda/12.2
          cd /projects/ctb/blokus-runner/_work/ocots/Blokus/Blokus/blokus-engine
          source .venv/bin/activate
          
          echo "GPU Information:"
          nvidia-smi
          
          python -u scripts/train.py --new --name "${{ needs.setup.outputs.experiment_name }}" --board-size "${{ needs.setup.outputs.board_size }}" --episodes "${{ needs.setup.outputs.episodes }}" --eval-freq "${{ needs.setup.outputs.eval_frequency }}" --eval-games "${{ needs.setup.outputs.eval_games }}" --log-freq "${{ needs.setup.outputs.log_frequency }}" --min-buffer "${{ needs.setup.outputs.min_buffer_size }}" --no-video | tee training_output.txt
          
          ACTUAL_EXP_DIR=$(grep "EXPERIMENT_DIR=" training_output.txt | cut -d'=' -f2)
          echo "EXPERIMENT_DIR=$ACTUAL_EXP_DIR" > job_results.txt
          
          METADATA_FILE="$ACTUAL_EXP_DIR/metadata.json"
          if [ -f "$METADATA_FILE" ]; then
            BEST_WIN_RATE=$(python -c "import json; print(json.load(open('$METADATA_FILE'))['best_win_rate'])")
            echo "BEST_WIN_RATE=$BEST_WIN_RATE" >> job_results.txt
          else
            echo "BEST_WIN_RATE=0.0" >> job_results.txt
          fi
          EOF
          
          # Submit job and wait
          echo "Submitting SLURM job..."
          JOB_ID=$(sbatch --parsable train_gpu.sh)
          echo "Job ID: $JOB_ID"
          
          # Wait for job
          while squeue -j $JOB_ID 2>/dev/null | grep -q $JOB_ID; do
            sleep 30
          done
          
          # Check results
          if sacct -j $JOB_ID --format=State --noheader | grep -q "COMPLETED"; then
            source job_results.txt
            echo "experiment_dir=$EXPERIMENT_DIR" >> "$GITHUB_OUTPUT"
            echo "best_win_rate=$BEST_WIN_RATE" >> "$GITHUB_OUTPUT"
            echo "success=true" >> "$GITHUB_OUTPUT"
          else
            cat slurm-${JOB_ID}.err || true
            exit 1
          fi

      - name: ðŸ“Š Set training outputs
        id: train
        run: |
          if [ "${{ steps.train_cpu.outcome }}" = "success" ]; then
            echo "experiment_dir=${{ steps.train_cpu.outputs.experiment_dir }}" >> "$GITHUB_OUTPUT"
            echo "best_win_rate=${{ steps.train_cpu.outputs.best_win_rate }}" >> "$GITHUB_OUTPUT"
            echo "success=${{ steps.train_cpu.outputs.success }}" >> "$GITHUB_OUTPUT"
          elif [ "${{ steps.train_gpu.outcome }}" = "success" ]; then
            echo "experiment_dir=${{ steps.train_gpu.outputs.experiment_dir }}" >> "$GITHUB_OUTPUT"
            echo "best_win_rate=${{ steps.train_gpu.outputs.best_win_rate }}" >> "$GITHUB_OUTPUT"
            echo "success=${{ steps.train_gpu.outputs.success }}" >> "$GITHUB_OUTPUT"
          else
            echo "success=false" >> "$GITHUB_OUTPUT"
          fi

      - name: ðŸ“Š Generate training plots
        if: steps.train.outputs.success == 'true'
        run: |
          cd blokus-engine
          if [ -d ".venv" ]; then source .venv/bin/activate; fi
          
          METRICS_FILE="${{ steps.train.outputs.experiment_dir }}/metrics.csv"
          if [ -f "$METRICS_FILE" ]; then
            python scripts/plot_metrics.py "$METRICS_FILE"
          fi

      - name: ðŸ“¦ Upload training artifacts
        if: steps.train.outputs.success == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: training-results
          path: |
            ${{ steps.train.outputs.experiment_dir }}/model.pt
            ${{ steps.train.outputs.experiment_dir }}/metadata.json
            ${{ steps.train.outputs.experiment_dir }}/metrics.csv
            ${{ steps.train.outputs.experiment_dir }}/training_plot.png
          retention-days: 30

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Commit results back to branch
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  commit-results:
    name: ðŸ’¾ Commit training results
    runs-on: ubuntu-latest
    needs: [train]
    if: needs.train.outputs.success == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download training artifacts
        uses: actions/download-artifact@v4
        with:
          name: training-results
          path: ${{ needs.train.outputs.experiment_dir }}

      - name: Commit and push results
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          git add ${{ needs.train.outputs.experiment_dir }}
          git commit -m "ðŸ¤– Training results: ${{ needs.train.outputs.experiment_dir }}
          
          Best win rate: ${{ needs.train.outputs.best_win_rate }}
          Runner: ${{ needs.determine-runner.outputs.has_gpu == 'true' && 'GPU (Occidata)' || 'CPU (GitHub)' }}"
          
          git push
