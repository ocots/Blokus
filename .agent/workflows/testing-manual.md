---
description: Manuel complet des tests pour le projet Blokus
---

# Testing Manual - Projet Blokus

**Version**: 1.0  
**Last Updated**: 2026-01-02  
**Purpose**: Guide complet pour Ã©crire et maintenir les tests du projet Blokus

---

## ğŸ“š Table des MatiÃ¨res

1. [Philosophie des Tests](#philosophie-des-tests)
2. [Types de Tests](#types-de-tests)
3. [Structure des Tests](#structure-des-tests)
4. [Standards de QualitÃ©](#standards-de-qualitÃ©)
5. [Bonnes Pratiques](#bonnes-pratiques)
6. [Exemples Concrets](#exemples-concrets)
7. [DÃ©bogage](#dÃ©bogage)
8. [Maintenance](#maintenance)

---

## Philosophie des Tests

### Objectifs Principaux
- **PrÃ©venir les bugs**: Chaque bug doit avoir un test qui l'aurait attrapÃ©
- **Documenter le code**: Les tests servent de documentation vivante
- **Faciliter le refactoring**: Tests robustes = confiance pour modifier
- **Garantir la qualitÃ©**: Maintenir un haut niveau de qualitÃ©

### Principes ClÃ©s
1. **Test First**: Ã‰crire les tests avant le code quand possible
2. **Test Isolation**: Chaque test doit Ãªtre indÃ©pendant
3. **Test ClartÃ©**: Les tests doivent Ãªtre faciles Ã  comprendre
4. **Test Couverture**: Couvrir tous les chemins critiques
5. **Test Maintenance**: Les tests doivent Ã©voluer avec le code

---

## Types de Tests

### 1. Unit Tests (Tests Unitaires)
**Objectif**: Tester une fonction/mÃ©thode isolÃ©e

**Quand Ã©crire**: 
- Pour chaque nouvelle fonction
- Pour chaque nouvelle mÃ©thode
- Pour chaque bug fixÃ©

**Exemple**:
```python
# Test unitaire simple
def test_game_manager_initialization():
    manager = GameManager(players=mock_players)
    assert len(manager.players) == 4
    assert manager.current_player_index == 0
```

**Ce qu'on teste**:
- âœ… La fonction fait ce qu'elle doit faire
- âœ… Les paramÃ¨tres sont validÃ©s
- âœ… Les cas limites sont gÃ©rÃ©s
- âœ… Les erreurs sont gÃ©rÃ©es

### 2. Logic Tests (Tests de Logique)
**Objectif**: Tester la logique mÃ©tier et les rÃ¨gles du jeu

**Quand Ã©crire**:
- Pour chaque rÃ¨gle du jeu
- Pour chaque transition d'Ã©tat
- Pour chaque validation

**Exemple**:
```python
# Test de logique mÃ©tier
def test_pass_turn_rejects_with_valid_moves():
    game = create_test_game()
    game.has_valid_move = lambda pid: True
    
    result = game.pass_turn(0)
    
    assert result is False
    assert not game.players[0].has_passed
```

**Ce qu'on teste**:
- âœ… Les rÃ¨gles du jeu sont respectÃ©es
- âœ… Les validations fonctionnent
- âœ… Les Ã©tats sont cohÃ©rents

### 3. Result Tests (Tests de RÃ©sultats)
**Objectif**: Tester que les outputs sont corrects

**Quand Ã©crire**:
- Pour chaque fonction qui retourne quelque chose
- Pour chaque effet secondaire
- Pour chaque mise Ã  jour d'Ã©tat

**Exemple**:
```python
# Test de rÃ©sultats
def test_play_move_updates_history():
    game = create_test_game()
    piece = create_test_piece()
    initial_history = len(game.move_history)
    
    game.play_move(piece, 10, 10)
    
    assert len(game.move_history) == initial_history + 1
    assert game.move_history[-1].piece_type == piece.type
```

**Ce qu'on teste**:
- âœ… Les types de retour sont corrects
- âœ… Les effets secondaires sont appliquÃ©s
- âœ… L'Ã©tat est mis Ã  jour

### 4. Integration Tests (Tests d'IntÃ©gration)
**Objectif**: Tester l'interaction entre plusieurs modules

**Quand Ã©crire**:
- Pour les workflows importants
- Pour les interactions critiques
- Pour les flux de donnÃ©es

**Exemple**:
```python
# Test d'intÃ©gration
def test_ai_controller_complete_turn():
    strategy = MockAIStrategy()
    animator = MockAIAnimator()
    controller = AIController(strategy, animator)
    game_context = create_game_context()
    
    result = controller.execute_turn(game_context)
    
    assert strategy.get_move.called
    assert animator.animate_placement.called
    assert game_context.play_move.called
```

**Ce qu'on teste**:
- âœ… Les modules interagissent correctement
- âœ… Les workflows complets fonctionnent
- âœ… Les donnÃ©es passent correctement

### 5. E2E Tests (Tests End-to-End)
**Objectif**: Tester le jeu complet du dÃ©but Ã  la fin

**Quand Ã©crire**:
- Pour les scÃ©narios critiques
- Pour les workflows utilisateur
- Pour les vÃ©rifications finales

**Exemple**:
```python
# Test E2E (optionnel)
def test_complete_ai_game():
    # Lancer jeu avec 4 IA
    # Jouer jusqu'Ã  la fin
    # VÃ©rifier rÃ©sultats
    pass
```

**Ce qu'on teste**:
- âœ… L'expÃ©rience utilisateur
- âœ… Les performances rÃ©elles
- âœ… Les scÃ©narios complets

---

## Structure des Tests

### Organisation des Fichiers
```
tests/
â”œâ”€â”€ unit/                    # Tests unitaires
â”‚   â”œâ”€â”€ test_game_manager.py
â”‚   â”œâ”€â”€ test_player.py
â”‚   â””â”€â”€ test_board.py
â”œâ”€â”€ integration/             # Tests d'intÃ©gration
â”‚   â”œâ”€â”€ test_ai_controller.py
â”‚   â””â”€â”€ test_game_flow.py
â”œâ”€â”€ e2e/                     # Tests E2E (optionnel)
â”‚   â””â”€â”€ test_complete_game.py
â””â”€â”€ fixtures/                # DonnÃ©es de test
    â”œâ”€â”€ mock_players.py
    â””â”€â”€ test_scenarios.py
```

### Nomination des Tests
- **Unit tests**: `test_<module>_<functionality>`
- **Integration tests**: `test_<workflow>_integration`
- **E2E tests**: `test_<scenario>_e2e`

### Structure d'un Test
```python
def test_descriptive_name():
    """
    Test description explaining what is being tested.
    
    Given: Initial state
    When: Action performed
    Then: Expected result
    """
    # ARRANGE - PrÃ©parer les donnÃ©es
    # ACT - ExÃ©cuter l'action
    # ASSERT - VÃ©rifier le rÃ©sultat
```

---

## Standards de QualitÃ©

### Couverture Requise
- **Unit tests**: 85% minimum
- **Logic tests**: 80% minimum
- **Integration tests**: 70% minimum
- **Overall**: 78% minimum

### QualitÃ© des Tests
1. **ClartÃ©**: Le nom du test doit dÃ©crire ce qu'il teste
2. **IndÃ©pendance**: Chaque test doit pouvoir s'exÃ©cuter seul
3. **RapiditÃ©**: Les tests doivent s'exÃ©cuter rapidement
4. **StabilitÃ©**: Les tests ne doivent pas Ãªtre "flaky"
5. **MaintenabilitÃ©**: Les tests doivent Ãªtre faciles Ã  maintenir

### Anti-patterns Ã  Ã‰viter
- âŒ Tests trop complexes
- âŒ Tests qui dÃ©pendent de l'ordre d'exÃ©cution
- âŒ Tests qui utilisent des donnÃ©es externes
- âŒ Tests sans assertions
- âŒ Tests qui testent trop de choses

---

## Bonnes Pratiques

### Ã‰crire des Tests
1. **AAA Pattern**: Arrange-Act-Assert
2. **Descriptive Names**: Noms qui dÃ©crivent le comportement
3. **One Assertion**: Une assertion par test quand possible
4. **Mocking**: Utiliser des mocks pour isoler le test
5. **Fixtures**: RÃ©utiliser les donnÃ©es de test

### Exemples de Bon Tests
```python
# âœ… Bon test
def test_game_manager_sets_starting_player_correctly():
    """Test that GameManager sets starting player correctly."""
    manager = GameManager(mock_players)
    
    manager.set_starting_player(2)
    
    assert manager.current_player_index == 2
    assert manager.current_player.id == 2
```

```python
# âŒ Mauvais test
def test_game_manager():
    manager = GameManager(mock_players)
    manager.set_starting_player(2)
    assert manager.current_player_index == 2
```

### Debugging des Tests
1. **Logs**: Utiliser des logs pour dÃ©boguer
2. **Prints**: Utiliser des prints pour les tests complexes
3. **Breakpoints**: Utiliser des breakpoints dans l'IDE
4. **Test Isolation**: ExÃ©cuter un test seul pour isoler le problÃ¨me

---

## Exemples Concrets

### Test d'une MÃ©thode Simple
```python
def test_player_add_piece():
    """Test that player can add a piece."""
    player = Player(id=0, name="Test")
    piece = Piece(type="I2", coords=[[0, 0]])
    
    player.add_piece(piece)
    
    assert len(player.remaining_pieces) == 20
    assert piece not in player.remaining_pieces
```

### Test d'une Classe Complexe
```python
def test_ai_controller_executes_turn():
    """Test that AIController executes a complete turn."""
    strategy = MockAIStrategy()
    animator = MockAIAnimator()
    controller = AIController(strategy, animator)
    game_context = create_game_context()
    player_state = PlayerStateMachine()
    
    controller.execute_turn(game_context, player_state)
    
    assert strategy.get_move.called
    assert animator.showThinkingIndicator.called
    assert animator.hideThinkingIndicator.called
```

### Test d'IntÃ©gration
```python
def test_game_flow_with_ai_players():
    """Test complete game flow with AI players."""
    game = Game(num_players=4)
    game.start_game()
    
    # Simulate AI turns
    for _ in range(10):
        if not game.is_game_over:
            current_player = game.current_player
            if current_player.is_ai:
                move = current_player.ai_strategy.get_move(game)
                if move:
                    game.play_move(move.piece, move.row, move.col)
                else:
                    game.pass_turn()
    
    assert game.is_game_over
    assert len(game.get_scores()) == 4
```

---

## DÃ©bogage

### ProblÃ¨mes Communs
1. **Test Flaky**: Test qui passe parfois mais pas toujours
2. **Test Lent**: Test qui prend trop de temps
3. **Test Complexe**: Test qui fait trop de choses
4. **Test DÃ©pendant**: Test qui dÃ©pend d'autres tests

### Solutions
1. **Isolation**: Isoler le problÃ¨me en exÃ©cutant un test seul
2. **Logging**: Ajouter des logs pour voir ce qui se passe
3. **Mocking**: Utiliser des mocks pour contrÃ´ler les dÃ©pendances
4. **Refactoring**: Simplifier le test ou le code testÃ©

### Outils
- **pytest**: Framework de test
- **coverage**: Mesurer la couverture
- **pytest-watch**: ExÃ©cuter les tests automatiquement
- **pytest-xdist**: ExÃ©cuter les tests en parallÃ¨le

---

## Maintenance

### Quand Mettre Ã  Jour les Tests
1. **Nouveau code**: Toujours ajouter des tests
2. **Bug fix**: Ajouter un test qui aurait attrapÃ© le bug
3. **Refactoring**: Mettre Ã  jour les tests existants
4. **Nouvelle fonctionnalitÃ©**: Couvrir la nouvelle fonctionnalitÃ©

### RÃ©vision des Tests
1. **Code Review**: Faire reviewer les tests comme le code
2. **Coverage**: VÃ©rifier la couverture rÃ©guliÃ¨rement
3. **Performance**: Surveiller la performance des tests
4. **QualitÃ©**: Maintenir la qualitÃ© des tests

### Documentation
- **README**: Documenter comment exÃ©cuter les tests
- **Comments**: Ajouter des commentaires dans les tests complexes
- **Examples**: Garder des exemples de bons tests
- **Guidelines**: Maintenir ce manuel Ã  jour

---

## RÃ©fÃ©rences

### Documentation Interne
- [Test Types Guide](../docs/guides/test-types-guide.md)
- [Test Coverage Analysis](../docs/reports/test-types-analysis.md)
- [Test Implementation Summary](../docs/reports/final-test-summary.md)

### Externes
- [pytest documentation](https://docs.pytest.org/)
- [Python testing best practices](https://docs.python.org/3/library/unittest.html)
- [Testing strategies](https://martinfowler.com/articles/mocksArentStubs.html)

---

## Conclusion

Les tests sont un investissement dans la qualitÃ© et la maintenabilitÃ© du code. En suivant ce manuel, nous pouvons garantir que le projet Blokus reste robuste, maintenable et de haute qualitÃ©.

**Rappelez-vous**: Un bug sans test est un bug qui reviendra.
