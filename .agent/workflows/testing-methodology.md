---
description: MÃ©thodologie complÃ¨te de dÃ©veloppement guidÃ© par les tests
---

# MÃ©thodologie de DÃ©veloppement GuidÃ© par les Tests

**Version**: 1.0  
**Last Updated**: 2026-01-02  
**Purpose**: Guide mÃ©thodologique pour le dÃ©veloppement TDD et l'Ã©criture de tests

---

## ðŸŽ¯ Philosophie Fondamentale

### Le Principe d'Or
**NE JAMAIS modifier un test pour le faire passer**  
Un test qui Ã©choue est une **information prÃ©cieuse**, pas un problÃ¨me Ã  Ã©liminer.

### MentalitÃ© Correcte
- âŒ **Mauvaise**: "Comment faire passer ce test ?"
- âœ… **Bonne**: "Que m'indique ce test sur mon code ?"

### Le Test est SpÃ©cification
Un test n'est pas un obstacle, c'est la **dÃ©finition du comportement attendu**.

---

## ðŸ”„ MÃ©thodologie TDD (Test-Driven Development)

### Les 3 Cycles du TDD

#### 1. ðŸ”´ RED - Ã‰crire un test qui Ã©choue
```python
# Ã‰crire le test AVANT le code
def test_game_manager_sets_starting_player():
    """Test that GameManager sets starting player correctly."""
    manager = GameManager(mock_players)
    
    manager.set_starting_player(2)
    
    assert manager.current_player_index == 2
    assert manager.current_player.id == 2
```

**Pourquoi il doit Ã©chouer**:
- âœ… Confirme que le test fonctionne
- âœ… DÃ©finit clairement le besoin
- âœ… Ã‰vite les faux positifs

#### 2. ðŸŸ¢ GREEN - Faire passer le test (MAIS correctement)
```python
# ImplÃ©mentation MINIMALE mais CORRECTE
def set_starting_player(self, player_id: int) -> None:
    """Set starting player by ID."""
    for player in self.players:
        if player.id == player_id:
            self.current_player_index = self.players.index(player)
            return
    raise ValueError(f"Player with ID {player_id} not found")
```

**Principes**:
- âœ… **Code minimal**: Juste assez pour faire passer le test
- âœ… **Code correct**: Respecte les rÃ¨gles mÃ©tier
- âœ… **Pas de tricherie**: Ne pas modifier le test

#### 3. ðŸ”„ REFACTOR - AmÃ©liorer le code
```python
# AmÃ©liorer la structure sans changer le comportement
def set_starting_player(self, player_id: int) -> None:
    """Set starting player by ID."""
    player = self._find_player_by_id(player_id)
    if player is None:
        raise ValueError(f"Player with ID {player_id} not found")
    self.current_player_index = self.players.index(player)

def _find_player_by_id(self, player_id: int) -> Optional[Player]:
    """Find player by ID - helper method for reuse."""
    for player in self.players:
        if player.id == player_id:
            return player
    return None
```

**Principes**:
- âœ… **Comportement inchangÃ©**: Les tests passent toujours
- âœ… **Code plus propre**: Meilleure structure
- âœ… **RÃ©utilisabilitÃ©**: Extraire les helpers

---

## ðŸ“Š Ordre d'Ã‰criture des Tests

### Progression RecommandÃ©e

#### Phase 1: Tests Unitaires (Base)
```python
# 1. Tester les mÃ©thodes simples
def test_player_initialization():
    player = Player(id=0, name="Alice")
    assert player.id == 0
    assert player.name == "Alice"

# 2. Tester les cas limites
def test_player_with_negative_id():
    with pytest.raises(ValueError):
        Player(id=-1, name="Invalid")

# 3. Tester les Ã©tats
def test_player_initial_pieces():
    player = Player(id=0, name="Alice")
    assert len(player.remaining_pieces) == 21
```

#### Phase 2: Tests de Logique (RÃ¨gles)
```python
# 4. Tester les rÃ¨gles mÃ©tier
def test_player_cannot_pass_with_valid_moves():
    player = create_test_player()
    game = create_test_game_with_valid_moves(player)
    
    result = player.try_pass_turn(game)
    
    assert result is False
    assert player.status != PlayerStatus.PASSED

# 5. Tester les transitions d'Ã©tat
def test_player_status_transitions():
    player = Player(id=0, name="Alice")
    
    player.start_turn()
    assert player.status == PlayerStatus.ACTIVE
    
    player.pass_turn()
    assert player.status == PlayerStatus.PASSED
```

#### Phase 3: Tests de RÃ©sultats (Outputs)
```python
# 6. Tester les retours
def test_game_manager_returns_correct_scores():
    game = create_test_game()
    scores = game.get_scores()
    
    assert isinstance(scores, list)
    assert len(scores) == 4
    assert all(isinstance(score, int) for score in scores)

# 7. Tester les effets secondaires
def test_play_move_updates_history():
    game = create_test_game()
    initial_count = len(game.move_history)
    
    game.play_move(test_piece, 10, 10)
    
    assert len(game.move_history) == initial_count + 1
```

#### Phase 4: Tests d'IntÃ©gration (Interactions)
```python
# 8. Tester les interactions
def test_ai_controller_with_strategy():
    strategy = MockAIStrategy()
    controller = AIController(strategy)
    game = create_test_game()
    
    controller.execute_turn(game)
    
    assert strategy.get_move.called
    assert game.move_history[-1].player_id == 0

# 9. Tester les workflows
def test_complete_turn_flow():
    game = create_test_game()
    player = game.current_player
    
    player.start_turn()
    move = player.ai_strategy.get_move(game)
    game.play_move(move.piece, move.row, move.col)
    player.end_turn()
    
    assert player.status == PlayerStatus.WAITING
    assert len(game.move_history) > 0
```

#### Phase 5: Tests E2E (Optionnel)
```python
# 10. Tester les scÃ©narios complets
def test_complete_game_with_4_players():
    game = Game(num_players=4)
    game.start_game()
    
    while not game.is_game_over:
        current_player = game.current_player
        if current_player.is_ai:
            move = current_player.ai_strategy.get_move(game)
            if move:
                game.play_move(move.piece, move.row, move.col)
            else:
                game.pass_turn()
    
    assert game.is_game_over
    assert len(game.get_winner()) == 1
```

---

## ðŸš¨ Processus de Diagnostic des Ã‰checs

### Ã‰tape 1: Analyser l'Ã‰chec
```python
# Ã‰chec typique
FAILED test_game_manager_sets_starting_player.py::test_set_starting_player
AssertionError: assert 0 == 2
Expected: 2
Actual: 0
```

### Ã‰tape 2: Poser les Bonnes Questions
1. **Le test est-il correct ?**
   - L'assertion reflÃ¨te-t-elle le besoin rÃ©el ?
   - Les donnÃ©es de test sont-elles valides ?

2. **Le comportement attendu est-il correct ?**
   - Est-ce que le code DEVRAIT faire Ã§a ?
   - Est-ce que la spÃ©cification est bonne ?

3. **Le code implÃ©mente-t-il correctement le comportement ?**
   - Est-ce un bug d'implÃ©mentation ?
   - Est-ce un bug de conception ?

### Ã‰tape 3: DÃ©cider de l'Action

| ScÃ©nario | Action | Raison |
|----------|--------|--------|
| Test incorrect | ðŸ“ **Modifier le test** | Le test ne reflÃ¨te pas le besoin |
| SpÃ©cification incorrecte | ðŸ¤” **Revoir la spÃ©cification** | Le besoin est mal dÃ©fini |
| Code incorrect | ðŸ”§ **Corriger le code** | L'implÃ©mentation est fausse |
| Code manquant | âž• **ImplÃ©menter le code** | FonctionnalitÃ© non implÃ©mentÃ©e |

---

## ðŸ”„ Alternance Code-Tests

### StratÃ©gie RecommandÃ©e

#### DÃ©veloppement d'une Nouvelle FonctionnalitÃ©
```python
# 1. Ã‰crire le test principal
def test_new_feature_basic_functionality():
    feature = NewFeature()
    result = feature.do_something()
    assert result == expected_value

# 2. ImplÃ©menter le minimum
class NewFeature:
    def do_something(self):
        return expected_value

# 3. Ajouter les tests de cas limites
def test_new_feature_edge_cases():
    feature = NewFeature()
    
    with pytest.raises(ValueError):
        feature.do_something(None)
    
    with pytest.raises(ValueError):
        feature.do_something("invalid")

# 4. ImplÃ©menter la validation
class NewFeature:
    def do_something(self, input_data):
        if input_data is None or input_data == "invalid":
            raise ValueError("Invalid input")
        return expected_value

# 5. Ajouter les tests d'intÃ©gration
def test_new_feature_integration():
    feature = NewFeature()
    system = System(feature)
    
    result = system.process_data(test_data)
    assert result.success is True

# 6. ImplÃ©menter l'intÃ©gration
# ... et continuer le cycle
```

### RÃ¨gles d'Alternance
1. **Toujours Ã©crire le test en premier**
2. **ImplÃ©menter juste assez pour faire passer**
3. **Ajouter des tests avant d'ajouter du code**
4. **Refactoriser aprÃ¨s chaque test qui passe**
5. **Ne jamais modifier un test pour le faire passer**

---

## ðŸŽ¯ Bonnes Pratiques de Diagnostic

### Checklist de Diagnostic
- [ ] Le test est-il lisible et comprÃ©hensible ?
- [ ] L'assertion est-elle prÃ©cise ?
- [ ] Les donnÃ©es de test sont-elles valides ?
- [ ] Le comportement attendu est-il documentÃ© ?
- [ ] Le message d'erreur est-il clair ?

### Anti-patterns Ã  Ã‰viter
```python
# âŒ ANTI-PATTERN: Modifier le test pour le faire passer
def test_something():
    # Le test Ã©choue
    assert some_function() == 42
    
    # On modifie le test pour qu'il passe
    # assert some_function() == get_actual_value()  # MAUVAIS !

# âœ… BONNE PRATIQUE: Comprendre pourquoi Ã§a Ã©choue
def test_something():
    # Le test Ã©choue -> analyser pourquoi
    assert some_function() == 42  # Garder l'assertion originale
    # Corriger le code pour qu'il retourne 42
```

---

## ðŸ“ˆ MÃ©triques de QualitÃ©

### Indicateurs de Bonne MÃ©thodologie
- âœ… **Temps de cycle**: < 5 minutes par cycle RED-GREEN-REFACTOR
- âœ… **Taille des implÃ©mentations**: < 10 lignes par GREEN
- âœ… **Couverture**: Augmente progressivement
- âœ… **Tests flaky**: 0%

### Signes d'Alerte
- âŒ Tests modifiÃ©s aprÃ¨s Ã©criture
- âŒ ImplÃ©mentations complexes avant les tests
- âŒ Tests qui ne testent rien
- âŒ Couverture qui baisse

---

## ðŸ”„ Workflow Complet

### Pour une Nouvelle FonctionnalitÃ©
1. **Comprendre le besoin** (documentation, discussion)
2. **Ã‰crire le test principal** (RED)
3. **ImplÃ©menter le minimum** (GREEN)
4. **Ajouter les tests de cas limites** (RED)
5. **ImplÃ©menter la validation** (GREEN)
6. **Ajouter les tests d'intÃ©gration** (RED)
7. **ImplÃ©menter l'intÃ©gration** (GREEN)
8. **Refactoriser** (REFACTOR)
9. **RÃ©pÃ©ter** jusqu'Ã  couverture complÃ¨te

### Pour un Bug Fix
1. **Reproduire le bug avec un test** (RED)
2. **VÃ©rifier que le test Ã©choue** (CONFIRMATION)
3. **Corriger le bug** (GREEN)
4. **Ajouter des tests de rÃ©gression** (PLUS DE RED)
5. **ImplÃ©menter si nÃ©cessaire** (GREEN)
6. **Refactoriser** (REFACTOR)

---

## ðŸŽ¯ Conclusion

La mÃ©thodologie TDD n'est pas seulement une technique, c'est une **philosophie de dÃ©veloppement**. Le test n'est pas l'ennemi, il est ton **guide**.

**Rappelez-vous**:
- Un test qui Ã©choue est une **opportunitÃ© d'apprendre**
- La qualitÃ© vient de la **discipline**, pas des raccourcis
- Le code est **maintenable** grÃ¢ce aux tests, pas malgrÃ© eux

**Le test passe quand le code est correct, pas l'inverse.**
